# より理解をすすめるために

学習手順（01）を一通り実施した人が、「自分たちのデータで同じことを実現する」ために理解しておくべき概念をまとめる。

---

## 1. データの流れを理解する

### PoC で体験した全体像

```
CSV ファイル
  │
  │ ① 取り込み・変換
  ▼
Logstash（パイプライン）
  │
  │ ② 蓄積
  ▼
Elasticsearch（インデックス）
  │
  ├──③ 可視化──────▶ Kibana（ダッシュボード）
  │
  ├──④ 異常検知(GUI)──▶ Elasticsearch ML → Anomaly Explorer
  │
  ├──⑤ 異常検知(ML)──▶ Python → prediction-results インデックス
  │
  └──⑥ アラート─────▶ ElastAlert2 → 通知（メール/Slack等）
```

自分たちで構築するとき、まず考えるべきは **「自分たちのデータはどこにあり、どうやって Elasticsearch に入れるか」** という①②の部分。

### 各コンポーネントが担う役割

| コンポーネント | PoC での役割 | 実運用で担う役割 |
|---|---|---|
| **Logstash** | CSV を読んで Elasticsearch に投入 | データソース（DB/API/ファイル/MQ）から取り込み、変換して投入 |
| **Elasticsearch** | データを蓄積・検索・ML分析 | 時系列データの蓄積、全文検索、集計、異常検知 |
| **Kibana** | ダッシュボード表示・ML操作 | 運用者向けの監視画面、分析ツール |
| **ElastAlert2** | 条件に合うデータの通知 | リアルタイム監視・アラート通知 |
| **Python ML** | 独自モデルの学習・推論 | 高度な異常検知（Elasticsearch ML では対応困難な場合） |

---

## 2. Elasticsearch の基本概念

### インデックスとは何か

Elasticsearch における「インデックス」は、リレーショナルDBにおける「テーブル」に近い概念。

```
リレーショナルDB         Elasticsearch
─────────────          ──────────────
データベース            → クラスタ
テーブル               → インデックス
行（レコード）         → ドキュメント
列（カラム）           → フィールド
スキーマ               → マッピング
```

PoC では以下のインデックスを使った:

| インデックス | 内容 | 作成方法 |
|---|---|---|
| `sensor-data-2026.01` | 1月のセンサーデータ | Logstash が自動作成 |
| `sensor-data-2026.02` | 2月のセンサーデータ | Logstash が自動作成 |
| `sensor-data-2026.03` | 3月のセンサーデータ | Logstash が自動作成 |
| `prediction-results` | Python ML の推論結果 | Python スクリプトが作成 |

### なぜ月別にインデックスを分けるのか

時系列データは「古いデータを削除したい」「直近のデータだけ高速に検索したい」という要件がある。月別にインデックスを分けることで:

- **データの保持期間管理**: 古い月のインデックスだけ削除できる
- **検索パフォーマンス**: 特定月だけを対象にした検索が高速
- **ストレージ管理**: 古いインデックスを圧縮・アーカイブできる

PoC の Logstash パイプラインでは `sensor-data-%{+YYYY.MM}` というパターンで自動的に月別インデックスを作成していた。

### マッピング（スキーマ）

Elasticsearch は JSON ドキュメントを扱うが、各フィールドの「型」を定義する必要がある。これをマッピングと呼ぶ。

```json
{
  "@timestamp": "2026-01-01T00:00:00Z",  ← date 型
  "device_id": "pump-01",                 ← keyword 型（完全一致検索用）
  "vibration": 3.15,                      ← float 型
  "temperature": 44.79,                   ← float 型
  "current": 8.82                         ← float 型
}
```

重要な型の使い分け:

| 型 | 用途 | 例 |
|---|---|---|
| `date` | タイムスタンプ、時系列の軸 | `@timestamp` |
| `float` / `double` | 数値データ、集計対象 | `vibration`, `temperature` |
| `keyword` | 完全一致検索、グルーピング | `device_id`, `alert_level` |
| `text` | 全文検索（部分一致） | `description`, `error_message` |

> **よくある失敗**: 文字列フィールドが `text` 型になると、Kibana で「グルーピングに使えない」という問題が起きる。グルーピングに使いたいフィールドは `keyword` 型にする。PoC では Logstash パイプラインの `mutate { convert }` で型を明示的に指定していた。

### Data View（データビュー）

Kibana で Elasticsearch のデータを扱うには、まず Data View を作成する。これは「どのインデックスをどういう名前で参照するか」の定義。

- `sensor-data-*` → `sensor-data-2026.01`, `sensor-data-2026.02`, `sensor-data-2026.03` をまとめて参照
- Timestamp field に `@timestamp` を指定 → 時間範囲での絞り込みが可能に

---

## 3. データ取り込みパイプラインを理解する

### Logstash パイプラインの3段階

PoC で使った `logstash/pipeline/sensor-data.conf` は以下の3段階で構成されている:

```
input（入力）→ filter（変換）→ output（出力）
```

**input**: データをどこから読むか
```
file { path => "/data/sensor_data.csv" }    # CSV ファイル
# 他にも: jdbc（DB）、kafka、beats、http など
```

**filter**: データをどう変換するか
```
csv { columns => [...] }        # CSV をフィールドに分割
date { match => [...] }         # 文字列をタイムスタンプに変換
mutate { convert => {...} }     # 型変換（string → float 等）
```

**output**: データをどこに送るか
```
elasticsearch {
  hosts => ["http://elasticsearch:9200"]
  index => "sensor-data-%{+YYYY.MM}"     # 月別インデックスに投入
}
```

### 自分のデータに適用するとき考えること

| 検討項目 | 質問 | PoC での答え |
|---|---|---|
| データソース | データはどこにある？ | CSV ファイル |
| データ形式 | どんなフォーマット？ | CSV（カンマ区切り） |
| タイムスタンプ | 時刻フィールドはある？フォーマットは？ | `timestamp` 列、`yyyy-MM-dd HH:mm:ss` |
| 数値フィールド | どのフィールドが数値？ | vibration, temperature, current |
| カテゴリフィールド | グルーピングに使うフィールドは？ | device_id |
| データ量 | 1日あたり何件？ | 約432件（3台×144回/日） |
| リアルタイム性 | リアルタイム取込が必要？ | 不要（バッチ） |

---

## 4. 異常検知の考え方

### 2つのアプローチの違い

PoC では2つの異常検知を体験した。それぞれの特性を理解しておく。

#### Elasticsearch ML（教師なし学習）

```
「正常パターンを学習し、そこから外れたものを異常とみなす」
```

- **入力**: センサーデータそのもの（vibration, temperature, current）
- **学習データ**: 正常・異常のラベル不要。データ全体から「通常の振る舞い」を学習
- **出力**: 異常スコア（0〜100）
- **メリット**: ラベル付けが不要、未知の異常パターンも検知できる
- **デメリット**: 「なぜ異常か」の解釈が難しい、正常な変化も異常と判定する場合がある

PoC で確認したこと:
- Anomaly Explorer で、故障日（1/20, 2/5, 2/15）の前にスコアが上昇していた
- つまり「通常と違う振る舞い」を自動的に検知できた

#### Python ML（教師あり学習 — LightGBM）

```
「過去の故障履歴をもとに、故障の前兆パターンを学習する」
```

- **入力**: センサーデータ + 故障履歴（failure_history.csv）
- **学習データ**: 「故障7日前〜故障日 = 異常（ラベル1）」「それ以外 = 正常（ラベル0）」
- **出力**: 異常確率（0.0〜1.0）
- **メリット**: 精度が高い（PoC で97%）、特徴量重要度で原因がわかる
- **デメリット**: 故障履歴が必要、学習データにない故障パターンは検知できない

PoC で確認したこと:
- 精度97%、異常の検出率78%
- 特徴量重要度: 振動の24h平均が最も重要 → 「振動の長期的な上昇傾向」が故障予兆

### どちらを使うべきか

| 状況 | 推奨アプローチ |
|---|---|
| 故障履歴がない、まだデータを集め始めた段階 | Elasticsearch ML（教師なし） |
| 故障履歴が十分にある（10件以上） | Python ML（教師あり）のほうが高精度 |
| まずは手軽に始めたい | Elasticsearch ML（コーディング不要） |
| 独自の特徴量やアルゴリズムを試したい | Python ML |
| 両方 | Elasticsearch ML で広く検知 + Python ML で高精度な判定 |

### 特徴量エンジニアリングとは

Python ML で使った「特徴量」は、生のセンサー値をそのまま使うのではなく、**分析に有効な形に加工した値**のこと。

PoC で生成した特徴量:

| 特徴量 | 意味 | なぜ有効か |
|---|---|---|
| `vibration_mean_1h` | 直近1時間の振動平均 | 短期的なトレンドを捉える |
| `vibration_std_1h` | 直近1時間の振動標準偏差 | 値のばらつき（不安定さ）を捉える |
| `vibration_mean_24h` | 直近24時間の振動平均 | 長期的なトレンドを捉える |
| `vibration_change_rate` | 振動の変化率 | 急激な変化を捉える |
| `corr_current_temp` | 電流と温度の相関 | センサー間の異常な関係性を捉える |

> **重要な考え方**: 「振動が 5.0 だから異常」ではなく「振動が過去24時間で徐々に上昇している」ことが異常のサイン。生の数値ではなく、**変化のパターン**を捉える特徴量が予知保全では重要。

---

## 5. アラートの設計思想

### 閾値ベース vs ML ベース

| 方式 | 仕組み | メリット | デメリット |
|---|---|---|---|
| 閾値ベース | 「振動 > 10.0 なら異常」 | シンプル、説明しやすい | 事前に適切な閾値を知る必要がある |
| ML ベース | 「予兆スコア > 0.7 なら異常」 | 複合的なパターンを検知 | モデルの学習が必要 |

PoC の ElastAlert2 は ML ベース（prediction-results の anomaly_score を監視）だが、実運用では**両方を組み合わせる**のが一般的:

```
レベル1: 閾値ベース（即時対応）
  → 振動 > 15.0 → 即座にアラート（明らかな異常）

レベル2: ML ベース（予兆検知）
  → anomaly_score > 0.7 → 注意喚起（故障の予兆）
```

### アラート疲れを防ぐ

アラートが多すぎると「またか」と無視されるようになる。これを「アラート疲れ」と呼ぶ。

PoC の ElastAlert2 で設定した対策:
- `realert: 30 minutes` — 同じアラートは30分間抑制
- `alert_level` による段階分け — normal/caution/warning/danger

実運用で追加すべき対策:
- 重要度に応じた通知先の分離（danger のみ電話、warning はメール等）
- 営業時間外の抑制
- 同一設備の連続アラートの集約

---

## 6. 設定ファイルの読み方

PoC で使った各設定ファイルの役割と、変更する際のポイント。

### docker-compose.yml

全コンテナの定義。変更頻度が高いポイント:
- `environment`: パスワードやメモリ設定
- `volumes`: データやコンフィグのマウント
- `depends_on`: コンテナの起動順序

### elasticsearch/config/elasticsearch.yml

Elasticsearch 本体の設定。重要な設定:
- `xpack.security`: セキュリティの有効/無効
- `xpack.ml.enabled`: ML 機能の有効/無効
- メモリ設定は `.env` の `ES_MEM_LIMIT` で制御

### logstash/pipeline/sensor-data.conf

データ取り込みの核。自分のデータに合わせてカスタマイズする箇所:
- `input`: データソースの接続情報
- `filter`: データ変換ルール（CSV列名、日付フォーマット、型変換）
- `output`: 出力先インデックス名のパターン

### elastalert/rules/anomaly-alert.yaml

アラートルール。カスタマイズする箇所:
- `index`: 監視対象のインデックス
- `filter`: アラート条件
- `alert`: 通知先（debug → email/slack 等）
- `realert`: 重複抑制の時間

---

## 7. まとめ: 自分で構築するために必要な5つの理解

1. **データの流れ**: 自分のデータがどこにあり、どうやって Elasticsearch に入れるか
2. **インデックス設計**: データをどう分割し、どんなマッピング（型定義）にするか
3. **異常検知の選択**: 教師なし/教師あり、どちらが自分の状況に合うか
4. **特徴量の考え方**: 生の数値ではなく「変化のパターン」を捉える
5. **アラート設計**: 誰に・何を・どのタイミングで通知するか

これらを踏まえた具体的な進め方は [03_今後の進め方.md](03_今後の進め方.md) を参照。
