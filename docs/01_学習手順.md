# ELKスタック予知保全PoC — 学習手順

ステップバイステップで、データ投入からダッシュボード作成まで体験する。

## 前提条件

- Docker Desktop がインストール済み
- Docker にメモリ 8GB 以上を割り当て済み（推奨 16GB）
  - Docker Desktop → Settings → Resources → Memory
- ディスク空き容量 20GB 以上

## Step 1: 環境起動

### 1-0. 環境変数ファイルの準備

`.env.sample` をコピーして `.env` を作成する（`.env` は `.gitignore` で除外されているため、リポジトリには含まれない）。

```powershell
cd D:\Develop\ELKスタック
copy .env.sample .env
```

必要に応じてパスワードやメモリ設定を変更する。デフォルト値のまま使用しても問題ない。

### 1-1. コンテナ起動

```powershell
docker compose up -d
```

初回はイメージのダウンロードに時間がかかる（約2-3GB）。

### 1-2. 起動確認

```powershell
# 全コンテナが running であることを確認
docker compose ps

# Elasticsearch の稼働確認（status: green or yellow が返ればOK）
curl -u elastic:changeme http://localhost:9200/_cluster/health?pretty
```

> **うまくいかない場合**: `docker compose logs elasticsearch` でログを確認。メモリ不足の場合は `.env` の `ES_MEM_LIMIT` を調整する。

### 1-3. kibana_system ユーザーのパスワード設定

Kibana が Elasticsearch に接続するために必要な初回設定。

```powershell
docker exec -it elasticsearch bin/elasticsearch-reset-password -u kibana_system -i
```

プロンプトが表示されたら、`.env` の `KIBANA_PASSWORD` と同じ値（`changeme`）を入力する。

設定後、Kibana コンテナを再起動する。

```powershell
docker compose restart kibana
```

### 1-4. Kibana にアクセス

ブラウザで http://localhost:5601 を開く。

- ユーザー名: `elastic`
- パスワード: `changeme`

> **日本語化について**: Kibana の UI は日本語で表示される（`kibana/config/kibana.yml` で `i18n.locale: "ja-JP"` を設定済み）。本手順書のメニュー名は英語表記だが、実際の画面では日本語に翻訳されて表示される。

---

## Step 2: データ投入を確認する

Logstash が `data/sensor_data.csv` を自動的に読み込んで Elasticsearch にインデックスしている。

### 2-1. 投入状況の確認

```powershell
# データ件数を確認（38,880 件前後になるはず）
curl -u elastic:changeme "http://localhost:9200/sensor-data-*/_count?pretty"
```

### 2-2. Kibana でデータを確認

1. Kibana にログイン
2. 左メニュー → **Management** → **Stack Management** → **Data Views**
3. **Create data view** をクリック
4. 以下を入力:
   - Name: `sensor-data`
   - Index pattern: `sensor-data-*`
   - Timestamp field: `@timestamp`
5. **Save data view to Kibana** をクリック
6. 左メニュー → **Discover** を開く
7. 左上の Data view で `sensor-data` を選択
8. 時間範囲を `2026-01-01 ～ 2026-03-31` に設定
9. センサーデータが表示されることを確認

> **ここで確認すべきこと**: `device_id`, `vibration`, `temperature`, `current` などのフィールドが正しくパースされているか。

---

## Step 3: Kibana で異常検知（GUI操作 — 推奨）

Elasticsearch ML を使い、コーディング不要で異常検知モデルを作成する。

### 3-1. ML ジョブの作成を開始

1. 左メニュー → **機械学習**（Machine Learning）
2. **異常検知**（Anomaly Detection）→ **ジョブを作成**（Create job）
3. データビュー `sensor-data` を選択
4. **マルチメトリック**（Multi-metric job）を選択

### 3-2. ウィザード ステップ1: 時間範囲

5. **「完全なデータを使用」** をクリック（全期間を分析対象にする）
6. **「次へ」** をクリック

### 3-3. ウィザード ステップ2: フィールドを選択

7. メトリックを追加のドロップダウンから、以下の3つを追加:
   - `Mean(vibration)` — 振動の平均
   - `Mean(temperature)` — 温度の平均
   - `Mean(current)` — 電流の平均
8. **影響**（Influencers）: `device_id.keyword` を選択
9. **バケットスパン**: `15m`（15分間隔で分析）を確認
10. **「次へ」** をクリック

> **フィールドの分割**: 設定するとデバイスごとに個別モデルが作られるが、未設定でも問題ない。

### 3-4. ウィザード ステップ3: ジョブの詳細

11. **ジョブID**: `sensor-anomaly-detection` と入力
12. グループ、ジョブの説明はそのままでOK
13. **「次へ」** をクリック

### 3-5. ウィザード ステップ4〜5: 検証・まとめ

14. 検証結果を確認して **「次へ」**
15. まとめ画面で設定を確認し、**「ジョブを作成」** をクリック

ジョブ作成後、過去データに対して自動的に分析が実行される。処理が完了するまで数分待つ。

### 3-6. 結果の確認

ジョブ作成完了後、結果を確認する。

1. 左メニュー → **機械学習** → **異常エクスプローラー**（Anomaly Explorer）
2. ジョブ `sensor-anomaly-detection` が選択されていることを確認
3. 時間範囲を `2026-01-01 ～ 2026-03-31` に設定
4. 以下を確認:
   - **Anomaly Swimlane**: 設備ごとの異常度が色の濃淡で表示される
   - 故障日（1/20, 2/5, 2/15）の前に異常スコアが上昇しているか？
   - どのセンサーが異常として検知されているか？

> **ここが一番の学びポイント**: サンプルデータには故障の7日前から異常パターンを仕込んでいるので、MLがその前兆を捉えられるかを確認する。

### 3-7. Anomaly Detection の結果をダッシュボードに追加

1. Anomaly Swimlane の画面で **ダッシュボードに追加** をクリック（または後のStep 5でダッシュボードに組み込む）

---

## Step 4: Python ML で異常検知（オプション・高度）

Elasticsearch ML で十分な場合はスキップしてよい。
独自の特徴量設計やアルゴリズムを試したい場合に実行する。

### 4-1. モデル学習

```powershell
docker exec python-ml python train_model.py
```

出力される内容:
- 取得件数（Elasticsearch からのデータ取得）
- 精度評価（classification report: 正常/異常の precision, recall, f1-score）
- 特徴量重要度 TOP5

### 4-2. バッチ推論

```powershell
docker exec python-ml python batch_inference.py
```

推論結果が `prediction-results` インデックスに書き込まれる。

### 4-3. 推論結果用の Data View を作成

1. Kibana → **Stack Management** → **Data Views**
2. **Create data view**:
   - Name: `prediction-results`
   - Index pattern: `prediction-results`
   - Timestamp field: `@timestamp`
3. Discover で推論結果を確認（`anomaly_score`, `alert_level` フィールド）

---

## Step 5: ダッシュボード作成

### 5-1. 新しいダッシュボードを作成

1. 左メニュー → **ダッシュボード** → **ダッシュボードを作成**

### 5-2. センサー値の時系列グラフ（振動）

1. **ビジュアライゼーションを作成** をクリック → Lens エディターが開く
2. 左の「利用可能なフィールド」から `@timestamp` を右の **横軸** にドラッグ&ドロップ
3. 左から `vibration` を **縦軸** にドラッグ&ドロップ
4. 縦軸の `vibration` をクリックし、集計方法を **平均** に変更
5. 左から `device_id.keyword` を **内訳** にドラッグ&ドロップ
6. 右上のグラフタイプを **折れ線**（Line）に変更
7. **保存して戻る** をクリック

### 5-3. センサー値の時系列グラフ（温度・電流）

同じ手順で以下の2つのグラフも追加する:

- **温度**: 縦軸に `temperature` の平均、内訳に `device_id.keyword`
- **電流**: 縦軸に `current` の平均、内訳に `device_id.keyword`

### 5-4. Anomaly Swimlane の追加

Anomaly Swimlane は Lens エディターではなく、**パネルの追加** から作成する。

1. ダッシュボード編集画面の上部ツールバーで **「パネルの追加」** をクリック
2. パネルの種類一覧から **「異常スイムレーン」**（Anomaly swim lane）を選択
3. 設定画面で:
   - **ジョブ**: `sensor-anomaly-detection` を選択
   - **表示方法**: `device_id.keyword`
4. **保存して戻る**

### 5-5. ダッシュボードの保存

1. 右上の **Save** をクリック
2. タイトル: `予知保全ダッシュボード`
3. Save

---

## Step 6: アラート通知の確認（ElastAlert2）

> **前提**: Step 4（Python ML）を実行済みで、`prediction-results` インデックスに推論結果が書き込まれていること。

### ElastAlert2 の仕組み

ElastAlert2 は **Elasticsearch のデータを定期的に監視し、条件に合うデータが見つかったら通知する**ツール。

```
prediction-results インデックス
  （Python ML の推論結果）
        │
        ▼
  ┌─────────────┐    1分ごとに     ┌──────────────────┐
  │ ElastAlert2 │───チェック──────▶│ anomaly_score    │
  │  (監視役)   │                  │ >= 0.7 のデータ  │
  └─────┬───────┘                  │ があるか？       │
        │                          └──────────────────┘
        │ 見つかった！
        ▼
  ┌─────────────┐
  │  アラート   │  → 現在は debug（ログ出力のみ）
  │  通知実行   │  → 実運用ではメール/Slack/Webhook等
  └─────────────┘
```

### 設定ファイルの構成

ElastAlert2 の設定は **基本設定**と**アラートルール**の2つに分かれている。

**1. 基本設定 — `elastalert/config.yaml`**

| 設定 | 値 | 意味 |
|------|-----|------|
| `run_every: minutes: 1` | 1分 | 1分ごとに Elasticsearch をチェックする |
| `buffer_time: minutes: 15` | 15分 | 直近15分のデータを検索対象にする |
| `es_host` / `es_port` | elasticsearch:9200 | 監視先の Elasticsearch |
| `writeback_index` | elastalert_status | ElastAlert2 自身の状態管理用インデックス |

**2. アラートルール — `elastalert/rules/anomaly-alert.yaml`**

```yaml
name: "予知保全 - 異常検知アラート"    # ルール名
type: any                              # 条件に合うデータがあれば即アラート
index: prediction-results              # 監視するインデックス

filter:                                # 検索条件
  - range:
      anomaly_score:
        gte: 0.7                       # 異常スコア 0.7 以上

realert:
  minutes: 30                          # 同じアラートは30分間抑制（重複防止）

alert:
  - debug                              # ログ出力のみ（実運用なら email 等に変更）
```

> **ポイント**: `buffer_time: 15 minutes` は「直近15分のデータだけを監視する」設定。実運用ではリアルタイムに推論結果が書き込まれるため、この設定で問題ない。今回のサンプルデータは過去データのため、通常のログ監視ではアラートが出ない。テスト方法は後述。

### 6-1. ElastAlert2 の動作確認

```powershell
# ElastAlert2 のログを確認
docker compose logs -f elastalert
```

起動時に以下のログが出ていれば正常に動作している:

```
Reading Elastic 8 index mappings:
...
Index elastalert_status already exists. Skipping index creation.
```

### 6-2. アラートルールのテスト

サンプルデータは過去のタイムスタンプのため、通常の監視ループでは検知されない。`elastalert-test-rule` コマンドで日付範囲を指定してテストする。

```powershell
docker exec elastalert elastalert-test-rule ^
  --start "2026-01-01T00:00:00" ^
  --end "2026-01-25T00:00:00" ^
  /opt/elastalert/rules/anomaly-alert.yaml
```

以下のようなアラートが出力されれば成功:

```
Queried rule 予知保全 - 異常検知アラート from 2026-01-01 ... : 955 / 955 hits
Alert for 予知保全 - 異常検知アラート at 2026-01-04T14:00:00Z:
━━━━━━━━━━━━━━━━━━━━━
⚠️ 予知保全アラート【caution】
━━━━━━━━━━━━━━━━━━━━━
■ 設備: pump-01
■ 予兆スコア: 0.848
■ 検知方法: ML推論（LightGBM）
■ 振動: 3.11 / 温度: 47.58 / 電流: 8.97
■ ダッシュボード: http://localhost:5601/app/dashboards
━━━━━━━━━━━━━━━━━━━━━
```

- `955 hits` — anomaly_score >= 0.7 のデータがすべて検知された
- `realert: 30 minutes` の設定により、30分以内の重複アラートは `Ignoring match for silenced rule` として抑制される

### 6-3. 実運用での通知先設定

現在は `debug`（ログ出力のみ）だが、`anomaly-alert.yaml` の `alert` セクションを変更するだけで通知先を切り替えられる。

```yaml
# メール通知
alert:
  - email
email:
  - "operator@example.com"
smtp_host: "smtp.example.com"

# Slack 通知
alert:
  - slack
slack_webhook_url: "https://hooks.slack.com/services/xxx/yyy/zzz"

# Webhook（Microsoft Teams 等）
alert:
  - post
http_post_url: "https://example.com/webhook"
```

### 6-4. Kibana のアラート機能（別のアプローチ）

ElastAlert2 を使わず、Kibana 組み込みのアラート機能を使うこともできる。

1. 左メニュー → **Management** → **Stack Management** → **Rules**
2. **Create rule** をクリック
3. Rule type: **Elasticsearch query**
4. 条件を設定してアラートを作成

---

## Step 7: 片付け

### 一時停止（データ保持）

```powershell
docker compose down
```

### 完全削除（データも消す）

```powershell
docker compose down -v
```

---

## 学習チェックリスト

各ステップの完了を確認する。

- [ ] Step 1: Docker 環境を起動し、Kibana にログインできた
- [ ] Step 2: Discover でセンサーデータを閲覧できた
- [ ] Step 3: Elasticsearch ML でウィザード（時間範囲→フィールド選択→ジョブ詳細→検証→作成）を完了できた
- [ ] Step 3: 異常エクスプローラーで故障日の前にセンサー異常が検知されることを確認できた
- [ ] Step 4: （オプション）Python ML で学習・推論を実行できた
- [ ] Step 5: ダッシュボードにグラフ・Metric・Anomaly Swimlane を配置できた
- [ ] Step 6: ElastAlert2 のログにアラートが出力されることを確認できた

## トラブルシューティング

### Elasticsearch が起動しない

```powershell
docker compose logs elasticsearch
```

- `max virtual memory areas vm.max_map_count [65530] is too low`: WSL2の場合、`wsl -d docker-desktop sysctl -w vm.max_map_count=262144` を実行
- `java.lang.OutOfMemoryError`: `.env` の `ES_MEM_LIMIT` を増やす

### Logstash がデータを読み込まない

```powershell
docker compose logs logstash
```

- `Permission denied`: `data/` フォルダのパーミッションを確認
- CSVのパスが正しいか確認（コンテナ内パスは `/data/sensor_data.csv`）

### Kibana に接続できない

- Elasticsearch が healthy になるまで待つ（`docker compose ps` で確認）
- `kibana_system` のパスワード設定（Step 1-3）が完了しているか確認

### Elasticsearch ML が使えない

- Trial ライセンスが有効か確認: `curl -u elastic:changeme http://localhost:9200/_license?pretty`
- ライセンスが切れた場合: `docker compose down -v` で再セットアップ
